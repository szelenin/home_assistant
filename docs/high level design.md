# Home Assistant

A lightweight, modular voice-controlled API orchestration system that supports multiple languages and can intelligently call APIs based on natural language commands.

## ğŸ¯ Project Overview

This project creates a voice assistant that:
- Runs efficiently on Raspberry Pi (tested on Pi 3B+ and Pi 4)
- Listens for a wake word using minimal CPU resources
- Processes voice commands in multiple languages
- Uses AI to understand intent and orchestrate API calls
- Provides a flexible architecture for switching between local and cloud providers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Raspberry Pi System                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Wake Word  â”‚â”€â”€â”€â”€â–¶â”‚    Audio     â”‚â”€â”€â”€â”€â–¶â”‚   Speech    â”‚ â”‚
â”‚  â”‚  Detection  â”‚     â”‚   Capture    â”‚     â”‚ Recognition â”‚ â”‚
â”‚  â”‚(OpenWakeWord)     â”‚              â”‚     â”‚  (Hybrid)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚         â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚         â”‚
â”‚                      â”‚      AI      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                      â”‚ Orchestrator â”‚                       â”‚
â”‚                      â”‚  (GPT/Claude)â”‚                       â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                             â”‚                               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                      â”‚     API      â”‚                       â”‚
â”‚                      â”‚   Manager    â”‚                       â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                             â”‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   Local APIs                         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚   Lights    â”‚  Temperature â”‚   Security â”‚  Custom  â”‚  â”‚
â”‚  â”‚    API      â”‚     API      â”‚     API    â”‚   APIs   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Core Features
- **Wake Word Detection**: Energy-efficient continuous listening
- **Multi-Language Support**: 20+ languages supported
- **Hybrid Recognition**: Automatic fallback from cloud to offline
- **AI-Powered Understanding**: Natural language processing for complex commands
- **Modular Architecture**: Easy to swap providers and add new capabilities

### Supported Voice Providers
- **Google Speech-to-Text** (default for cloud)
- **OpenAI Whisper API** (for complex commands)
- **Vosk** (offline fallback)
- **Azure Speech Services** (optional)

### Wake Word Solutions
- **OpenWakeWord** (recommended - free & open source)
- **Porcupine** (highest accuracy)
- **PocketSphinx** (most lightweight)

## ğŸ“‹ Requirements

### Hardware
- Raspberry Pi 3B+ or newer (Pi 4 recommended)
- USB Microphone or I2S MEMS microphone
- Speaker (USB, 3.5mm jack, or I2S)
- MicroSD card (16GB minimum)
- Stable internet connection (for cloud services)

### Software
- Raspberry Pi OS (Bullseye or newer)
- Python 3.8+
- PortAudio
- Git

## ğŸ› ï¸ Installation

### 1. System Setup
```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install system dependencies
sudo apt install -y \
    python3-pip \
    python3-venv \
    git \
    portaudio19-dev \
    python3-pyaudio \
    libatlas-base-dev \
    libgfortran5

# Install audio utilities
sudo apt install -y alsa-utils pulseaudio
```

### 2. Clone Repository
```bash
git clone https://github.com/szelenin/home_assistant.git
cd home_assistant
```

### 3. Python Environment
```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install Python packages
pip install -r requirements.txt
```

### 4. Configure Audio
```bash
# Test microphone
arecord -l  # List recording devices
arecord -D plughw:1,0 -d 5 test.wav  # Test recording
aplay test.wav  # Test playback

# Set default audio devices
sudo nano /etc/asound.conf
```

### 5. Download Models (for offline support)
```bash
# Download Vosk model
cd models
wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
unzip vosk-model-small-en-us-0.15.zip

# Download wake word models
python download_wake_models.py
```

## ğŸ“ Project Structure

```
home_assistant/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.yaml                 # Configuration file
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ wake_word/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ detector.py        # Wake word detection interface
â”‚   â”‚   â”œâ”€â”€ openwakeword.py    # OpenWakeWord implementation
â”‚   â”‚   â””â”€â”€ porcupine.py       # Porcupine implementation
â”‚   â”œâ”€â”€ speech/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ recognizer.py      # Speech recognition interface
â”‚   â”‚   â”œâ”€â”€ google_stt.py      # Google STT provider
â”‚   â”‚   â”œâ”€â”€ whisper.py         # OpenAI Whisper provider
â”‚   â”‚   â””â”€â”€ vosk_stt.py        # Vosk offline provider
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py    # AI command processing
â”‚   â”‚   â””â”€â”€ providers.py       # AI provider implementations
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ manager.py         # API endpoint manager
â”‚   â”‚   â””â”€â”€ endpoints/         # Local API implementations
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ audio.py           # Audio utilities
â”‚       â””â”€â”€ config.py          # Configuration manager
â”œâ”€â”€ models/                    # Offline models directory
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ examples/                  # Example API endpoints
â”‚   â”œâ”€â”€ lights_api.py
â”‚   â”œâ”€â”€ temperature_api.py
â”‚   â””â”€â”€ README.md
â””â”€â”€ scripts/
    â”œâ”€â”€ setup.sh              # Setup script
    â””â”€â”€ run_assistant.sh      # Start script
```

## âš™ï¸ Configuration

### config.yaml
```yaml
# Wake word configuration
wake_word:
  provider: "openwakeword"  # Options: openwakeword, porcupine, pocketsphinx
  models:
    - "hey_jarvis"
    - "ok_computer"
  sensitivity: 0.5

# Speech recognition configuration  
speech:
  provider: "hybrid"  # Options: google, whisper, vosk, hybrid
  primary:
    type: "google"
    language: "en-US"
  fallback:
    type: "vosk"
    model_path: "models/vosk-model-small-en-us-0.15"
  
# AI orchestrator configuration
ai:
  provider: "openai"  # Options: openai, anthropic, local
  model: "gpt-4"
  temperature: 0.7

# API endpoints configuration
apis:
  - name: "lights"
    description: "Control smart lights"
    base_url: "http://localhost:8001"
    endpoints:
      on:
        method: "POST"
        path: "/lights/on"
        description: "Turn lights on"
      off:
        method: "POST"
        path: "/lights/off"
        description: "Turn lights off"
        
# Audio configuration
audio:
  input_device: 1  # Use arecord -l to find
  sample_rate: 16000
  chunk_size: 512
```

### Environment Variables (.env)
```bash
# API Keys
OPENAI_API_KEY=your_openai_key_here
GOOGLE_CLOUD_KEY=your_google_key_here  # Optional
PICOVOICE_ACCESS_KEY=your_picovoice_key_here  # If using Porcupine

# Optional configurations
LOG_LEVEL=INFO
MAX_RECORDING_SECONDS=10
SILENCE_THRESHOLD=500
```

## ğŸ® Usage

### Basic Usage
```bash
# Start the assistant
python main.py

# Or use the convenience script
./scripts/run_assistant.sh
```

### Command Examples
```
You: "Hey Jarvis"
Assistant: *listening beep*
You: "Turn on the living room lights"
Assistant: "Living room lights turned on"

You: "Hey Jarvis"
Assistant: *listening beep*
You: "What's the temperature in the bedroom?"
Assistant: "The bedroom temperature is 22 degrees Celsius"
```

### Adding Custom APIs
1. Define your API in `config.yaml`
2. Implement the endpoint (see `examples/`)
3. Restart the assistant

Example API implementation:
```python
# examples/custom_api.py
from fastapi import FastAPI

app = FastAPI()

@app.post("/custom/action")
async def custom_action(params: dict):
    # Your logic here
    return {"status": "success", "message": "Action completed"}
```

## ğŸŒ Multi-Language Support

Configure language in `config.yaml`:
```yaml
speech:
  primary:
    type: "google"
    language: "es-ES"  # Spanish
    # Supported: en-US, es-ES, fr-FR, de-DE, it-IT, pt-BR, ja-JP, ko-KR, zh-CN
```

## ğŸ”§ Advanced Configuration

### Performance Tuning
```yaml
# For Raspberry Pi Zero/3A+
performance:
  mode: "low_power"
  wake_word_cpu_limit: 5  # Percentage
  buffer_size: 8192
  
# For Raspberry Pi 4
performance:
  mode: "balanced"
  wake_word_cpu_limit: 10
  buffer_size: 16384
```

### Custom Wake Words
```bash
# Train custom wake word with OpenWakeWord
python scripts/train_wake_word.py --word "custom_word" --samples 50
```

## ğŸ› Troubleshooting

### Common Issues

1. **No audio input detected**
   ```bash
   # Check audio devices
   arecord -l
   # Test recording
   arecord -D plughw:1,0 -f S16_LE -r 16000 test.wav
   ```

2. **High CPU usage**
   - Switch to lighter wake word model
   - Reduce sample rate to 8000Hz
   - Use PocketSphinx instead of OpenWakeWord

3. **Network timeouts**
   - Enable offline mode in config
   - Increase timeout values
   - Check internet connection

4. **Permission errors**
   ```bash
   # Add user to audio group
   sudo usermod -a -G audio $USER
   # Logout and login again
   ```

## ğŸ“Š Performance Metrics

| Component | CPU Usage (Pi 4) | CPU Usage (Pi 3) | Memory |
|-----------|------------------|------------------|---------|
| Wake Word | 3-5% | 5-8% | 50MB |
| Idle | <1% | <1% | 100MB |
| Recognition | 15-20% | 25-30% | 200MB |
| AI Processing | 5-10% | 10-15% | 150MB |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenWakeWord team for the efficient wake word detection
- Vosk project for offline speech recognition
- Raspberry Pi Foundation for the amazing hardware

## ğŸ“® Support

- Create an issue for bugs or feature requests
- Check the [Wiki](https://github.com/szelenin/home_assistant/wiki) for detailed guides
- Join our [Discord community](https://discord.gg/yourlink)

## ğŸ—ºï¸ Roadmap

- [ ] Home Assistant integration
- [ ] Custom skill framework
- [ ] Voice feedback/TTS
- [ ] Multi-room support
- [ ] Bluetooth speaker support
- [ ] Web dashboard for configuration
- [ ] Docker container support
- [ ] Voice training interface